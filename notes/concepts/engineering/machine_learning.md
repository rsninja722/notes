# machine learning

- **machine learning** - the creating of a model with parameters (large amount) and a cost function to evaluate performance
    - useful model - has parameters such that the cost function is low
    - training - changing parameters to minimize cost function

## example: spam filter

- goal - separate legitimate emails from spam/scams
- one approach: certain words and phrases indicate spam, create a vector based on which words indicate spam, filter based on the existence of the words/phrases

- vector $\vec{x}$ indicates the spam words
- $\vec{w} \cdot \vec{x} = b$ defines a hyperplane
- $\vec{w}^{*}$ and $\vec{b}^{*}$ define a model that predicts if a message $\vec{y}$ is spam

$$f(\vec{y}) = \text{sign}(\vec{w}^{*} \cdot \vec{y} - \vec{v}^{*}) = \begin{cases} 1 & \text{spam} \\\\ -1 & \text{no spam} \end{cases}$$

if only 2 words are considered, a **decision bounding** can be drawn as a line on a 2d graph

## Machine learning use cases

- financial sector leads in AI adoption

<details>
<summary>large list of applications</summary>
<ul>
<li>Portfolio management (robo-advisors)</li>
<li>Sentiment analysis</li>
<li>Drone navigation</li>
<li>Algorithmic trading</li>
<li>Satellite image analysis</li>
<li>Military surveillance and reconnaissance</li>
<li>License plate recognition</li>
<li>Speech recognition</li>
<li>Medical image analysis</li>
<li>Credit scoring and risk assessment</li>
<li>Optical Character Recognition (OCR)</li>
<li>Facial recognition</li>
<li>Document classification</li>
<li>Patient monitoring and wearable devices</li>
<li>Language modeling (e.g. GPT, BERT)</li>
<li>Genomics and bioinformatics</li>
<li>Automatic question answering</li>
<li>Object detection and recognition</li>
<li>Epidemic outbreak prediction</li>
<li>Chatbots and virtual agents</li>
<li>Customer behavior prediction</li>
<li>Email marketing optimization</li>
<li>Price optimization and dynamic pricing</li>
<li>Video game content generation</li>
<li>Generative art and music</li>
<li>Automatic content tagging and </li>classification
<li>Particle physics data analysis (e.g. CERN)</li>
<li>Autonomous vehicles (self-driving cars)</li>
<li>Climate modeling and prediction</li>
<li>Visual search (by photo)</li>
<li>Space exploration (e.g. navigation, </li>detection)
<li>Driver behavior analysis</li>
<li>Protein folding (e.g. AlphaFold)</li>
<li>Call center automation (e.g. voice bots)</li>
<li>Astronomical data classification</li>
<li>Traffic prediction and route optimization</li>
<li>Earthquake prediction</li>
<li>Speech-to-text services</li>
<li>Tracking animal populations</li>
<li>Understanding animal language</li>
<li>Disease diagnosis</li>
<li>Medical imaging analysis (MRI, CT, X-rays)</li>
<li>Malware and ransomware detection</li>
<li>Insurance risk scoring</li>
<li>User behavior analytics</li>
<li>Demand forecasting in ride-sharing</li>
<li>Spam and phishing detection</li>
<li>Quality control and defect detection</li>
<li>Biometric authentication</li>
<li>Plagiarism detection</li>
<li>Ad targeting and optimization</li>
<li>Demand forecasting</li>
<li>Recommender systems</li>
<li>Intelligent tutoring systems</li>
<li>Supply chain optimization</li>
<li>Crime prediction and prevention</li>
<li>Energy consumption optimization</li>
<li>Traffic management</li>
<li>Content moderation (e.g. offensive content)</li>
<li>Smart city infrastructure</li>
<li>Drug discovery & development</li>
<li>Fake news detection</li>
<li>Public health monitoring</li>
<li>Automated interview analysis</li>
<li>Policy impact simulation</li>
<li>Game AI (NPC behavior, dynamic difficulty)</li>
<li>Resource allocation optimization</li>
<li>Fraud detection in payments</li>
<li>Weather forecasting</li>
<li>Precision farming</li>
<li>Resume screening and candidate matching</li>
<li>Yield prediction</li>
<li>Employee attrition prediction</li>
<li>Soil quality analysis</li>
<li>Deepfake creation and detection</li>
<li>Text summarization</li>
<li>Livestock monitoring</li>
<li>Language translation</li>
<li>Loan default prediction</li>
</ul>
</details>

### natural language processing

- linguistic analysis
- document classification
- translation
- games
- conversion between text, images/speech
- chatbots
- grammar correction
- summarization
- sentiment analysis
- info extraction and search

### computer vision

- object detection
- health diagnoses
- self driving vehicles
- pest detection
- surveillance

### management

- farm monitoring
- recommendation systems

### simulation

- drug discovery
- bio-informatics


# large language models

## vulnerabilities

### slopsquatting

- attacker writes malicious code and publishes it under the name of a made up package that is frequently generated by a LLM

# types of machine learning
TODO

## supervised 

- task driven with labeled data
- wrong predictions cause weights to be adjusted
- aim is to arrive ata solution that is the best approximation of the ideal perfect (categorization) function
- **training set** - labeled data used to adjust weights
- **test set** - separate labeled data used to test if the model is accurate

### linear regression

goal: find a relationship between two parameters

the parameters (weights) in a linear equation are the model

$y' = \Beta_0 + \Beta_1 \cdot x_1 + \Beta_2 \cdot x_2 + \dots + \Beta_p \cdot x_p$

the linear equation is used to estimate the label

usually optimized using "least squares": $\Sum_{i=0}^{n} d^2$ 

optimal weights can be found with a derivation

#### least squares matrix dimensions

p = numb features, n = num instances

- $X = n \times p$
- $X^T = p \times n$
- $X^TX = p \times p$
- $(X^TX)^{-1} = p \times p$
- $(X^TX)^{-1}X^T = p \times n$
- $y = n \times 1$
- $(X^TX)^{-1}X^Ty = \Beta \text{ is } p \times 1$ 

### polynomial regression


a polynomial model is of the form:

$y' = \Beta_0 + \Beta_1 \cdot x_1 + \Beta_2 \cdot x_1^2 + \dots + \Beta_n \cdot x_1^n$

$+ \Beta_3 \cdot x_2 + \Beta_4 \cdot x_2^2 ...$

optimize the same way as for linear regression

## unsupervised

- no labels for data
- aim is to organize or group data
- represented as vectors, distance between is the data indicates similarity

## reinforcement

TODO

- decision process with a reward system producing a learned series of actions

# optimization methods

## gradient descent

derivative gives the slope of the function to follow to find a local minimum

- take the derivative of the loss function to determine the direction

# developing a model

- define a goal for what to accomplish
- define a testable hypothesis (usually about the existence of a certain relationship)

# definitions

- **operationalization** - defining how things are measured
    - example: subject knowledge is measured by test scores
    - poor operationalization can lead to optimization for the measure rather than the process that is being measured

- **datasets** - a set of examples with certain categories of features
- **classification task** - the goal of categorizing input data into different categories/classes
- **hyperparameters** - model settings that can be choosen manually or algorithmically
- **parameters** - weights the model learns
- **loss function**  - measures the difference between predicted output and true labels
    - to be optimized for by minimizing loss

## inference versus prediction

- **prediction** how can we use $X$ to predict $Y$
- **inference** - what is the nature of the relationship between $X$ and $Y$

## parametric

- parametric models have some predefined parameters
- more efficient needing less data
- more interpretable
- less flexible

##  vs non-parametric

- non-parametric models make no assumptions about the data
- less efficient needing more data
- less predictable
- more flexible
